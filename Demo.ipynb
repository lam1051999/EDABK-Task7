{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer  # binaryclass\n",
    "import cv2 as cv\n",
    "import os\n",
    "from Layer import Layer\n",
    "from NN import NN\n",
    "import numpy as np\n",
    "from sys import path\n",
    "path.append('..')\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import data\n",
    "\n",
    "path_human = 'Human-2'\n",
    "path_non_human = 'Non-Human-2'\n",
    "ones_human = np.ones((64*64, 1)).reshape(1, -1)\n",
    "\n",
    "# convert image shape to 1x4096 and put into a matrix ones_human\n",
    "\n",
    "for file in os.listdir(path_human):\n",
    "    path_img_human = path_human+'/'+file\n",
    "    image_human = cv.imread(path_img_human, 0).reshape(1, -1)\n",
    "    ones_human = np.vstack((ones_human, image_human))\n",
    "\n",
    "data_human = np.delete(ones_human, 0, 0)\n",
    "\n",
    "# N = number of data set, d is the number of features\n",
    "\n",
    "N, d = data_human.shape\n",
    "# print(N, d)\n",
    "\n",
    "\n",
    "ones_non_human = np.ones((64*64, 1)).reshape(1, -1)\n",
    "for file in os.listdir(path_non_human):\n",
    "    path_img_non_human = path_non_human+'/'+file\n",
    "    image_non_human = cv.imread(path_img_non_human, 0).reshape(1, -1)\n",
    "    ones_non_human = np.vstack((ones_non_human, image_non_human))\n",
    "\n",
    "data_non_human = np.delete(ones_non_human, 0, 0)\n",
    "\n",
    "feature_set = np.vstack((data_human, data_non_human))\n",
    "\n",
    "label_ones = np.ones((data_human.shape[0], 1))\n",
    "label_zeros = np.zeros((data_non_human.shape[0], 1))\n",
    "targets = np.vstack((label_ones, label_zeros))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    feature_set, targets, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a6e4c2888c08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# create the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NN' is not defined"
     ]
    }
   ],
   "source": [
    "### train the network\n",
    "### skip this step if already have the pre-trained weights\n",
    "\n",
    "# create the network\n",
    "nn_model = NN(X_train, Y_train)\n",
    "nn_model.add_layer(Layer(50, activation='relu'))\n",
    "nn_model.add_layer(Layer(25, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# fit the network\n",
    "nn_model.fit(iteration=20000, learning_rate=0.001)\n",
    "\n",
    "# plot cost function\n",
    "\n",
    "Y_train_pred = nn_model.predict(X_train)\n",
    "Y_test_pred = nn_model.predict(X_test)\n",
    "\n",
    "accuracy_train = np.sum(Y_train_pred == Y_train) / len(Y_train) * 100\n",
    "accuracy = np.sum(Y_test_pred == Y_test) / len(Y_test) * 100\n",
    "print(\"Train accuracy: \" + str(accuracy_train) + \"%\")\n",
    "print(\"Test accuracy: \" + str(accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 2: 98.64430147058823%\n"
     ]
    }
   ],
   "source": [
    "### predict with pretrained weights, still need to import data\n",
    "\n",
    "# create the network\n",
    "nn_model_2 = NN(X_train, Y_train)\n",
    "nn_model_2.add_layer(Layer(50, activation='relu'))\n",
    "nn_model_2.add_layer(Layer(25, activation='sigmoid'))\n",
    "\n",
    "# plot cost function\n",
    "# Y_train_pred_2 = nn_model_2.predict_pretrained_weights(X_train)\n",
    "Y_test_pred_2 = nn_model_2.predict_pretrained_weights(X_test)\n",
    "\n",
    "# accuracy_2_train = np.sum(Y_train_pred_2 == Y_train) / len(Y_train) * 100\n",
    "# print(\"Train accuracy 2: \" + str(accuracy_2_train) + \"%\")\n",
    "accuracy_2 = np.sum(Y_test_pred_2 == Y_test) / len(Y_test) * 100\n",
    "print(\"Test accuracy 2: \" + str(accuracy_2) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### link\n",
    "# https://stackoverflow.com/questions/37177811/crop-rectangle-returned-by-minarearect-opencv-python\n",
    "\n",
    "def crop_minAreaRect(rect, box, gray, frame):\n",
    "    mult = 1 # I wanted to show an area slightly larger than my min rectangle set this to one if you don't\n",
    "    W = rect[1][0]\n",
    "    H = rect[1][1]\n",
    "\n",
    "    Xs = [i[0] for i in box]\n",
    "    Ys = [i[1] for i in box]\n",
    "    x1 = min(Xs)\n",
    "    x2 = max(Xs)\n",
    "    y1 = min(Ys)\n",
    "    y2 = max(Ys)\n",
    "\n",
    "    rotated = False\n",
    "    angle = rect[2]\n",
    "\n",
    "    if angle < -45:\n",
    "        angle+=90\n",
    "        rotated = True\n",
    "\n",
    "    center = (int((x1+x2)/2), int((y1+y2)/2))\n",
    "    size = (int(mult*(x2-x1)),int(mult*(y2-y1)))\n",
    "\n",
    "    M = cv.getRotationMatrix2D((size[0]/2, size[1]/2), angle, 1.0)\n",
    "\n",
    "    cropped = cv.getRectSubPix(gray, size, center)    \n",
    "    cropped = cv.warpAffine(cropped, M, size)\n",
    "\n",
    "    croppedW = W if not rotated else H \n",
    "    croppedH = H if not rotated else W\n",
    "\n",
    "    croppedRotated = cv.getRectSubPix(cropped, (int(croppedW*mult), int(croppedH*mult)), (size[0]/2, size[1]/2))\n",
    "#     cv.circle(frame, center, 10, (0,255,0), -1) # again this was mostly for debugging purposes\n",
    "#     cv.rectangle(frame, \n",
    "#                  (int(center[0] - croppedW/2), int(center[1] - croppedH/2)), \n",
    "#                  (int(center[0] + croppedW/2), int(center[1] + croppedH/2)), \n",
    "#                  (255, 255, 255), \n",
    "#                  2) # again this was mostly for debugging purposes\n",
    "    \n",
    "    return croppedRotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test with video\n",
    "\n",
    "backSub = cv.BackgroundSubtractorMOG2(detectShadows=False)\n",
    "capture = cv.VideoCapture('12.mp4')\n",
    "fps = 30\n",
    "MIN_AREA = 600\n",
    "\n",
    "if not capture.isOpened:\n",
    "    print('Unable to open the video')\n",
    "    exit(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    # convert to gray + resize + apply filter\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    gray_copy = gray.copy()\n",
    "    gray = cv.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    fgMask = backSub.apply(gray)\n",
    "    fgMask = cv.medianBlur(fgMask,5)\n",
    "    \n",
    "    # get contours\n",
    "    cnts = cv.findContours(\n",
    "        fgMask.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    \n",
    "    for c in cnts:\n",
    "        rect = cv.minAreaRect(c)\n",
    "        if (rect[1][0]*rect[1][1]) < MIN_AREA:\n",
    "            continue\n",
    "        \n",
    "        box = cv.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        cv.drawContours(frame,[box],0,(0,255,0),2)\n",
    "        \n",
    "        img_crop = crop_minAreaRect(rect, box, gray_copy, frame)       \n",
    "        img_crop = cv.resize(img_crop, (64,64), interpolation = cv.INTER_AREA)\n",
    "        \n",
    "        Y_box_pred = np.sum(nn_model_2.predict(img_crop.reshape(1, -1)))\n",
    "        \n",
    "        if Y_box_pred == 1:\n",
    "            cv.putText(frame, \"Person\", (box[2][0], box[2][1]),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        if Y_box_pred == 0:\n",
    "            cv.putText(frame, \"Non\", (box[2][0], box[2][1]),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         if cv.contourArea(c) < MIN_AREA:\n",
    "#             continue\n",
    "\n",
    "#         (x, y, w, h) = cv.boundingRect(c)\n",
    "#         cut_gray = gray_copy[y:y+h,x:x+w]\n",
    "#         cut_gray = cv.resize(cut_gray, (64,64), interpolation = cv.INTER_AREA)\n",
    "#         Y_box_pred = np.sum(nn_model_2.predict(cut_gray.reshape(1, -1)))\n",
    "#         if Y_box_pred == 1:\n",
    "#             cv.putText(frame, \"Person\", (x, y-10),\n",
    "#                cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "#         if Y_box_pred == 0:\n",
    "#             cv.putText(frame, \"Non\", (x, y-10),\n",
    "#                cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "#         cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  \n",
    "        \n",
    "    cv.imshow('Frame', frame)\n",
    "#     cv.imshow('FG Mask', fgMask)\n",
    "#     cv.imshow('Gray copy', gray_copy)\n",
    "    if cv.waitKey(int((1/fps)*1000)) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
